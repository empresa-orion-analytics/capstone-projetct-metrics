# ğŸ“Š Capstone Project â€“ Metrics Platform

![Arquitetura da Plataforma](Docs/arquitetura.png)

Este repositÃ³rio contÃ©m a implementaÃ§Ã£o de uma **plataforma de dados analÃ­ticos** baseada em arquitetura *Lakehouse*, com separaÃ§Ã£o clara entre **ingestÃ£o, processamento, publicaÃ§Ã£o e consumo de dados**.

O objetivo do projeto Ã© demonstrar, de ponta a ponta, como dados brutos podem ser transformados em **informaÃ§Ã£o confiÃ¡vel e pronta para consumo por ferramentas de BI**, seguindo boas prÃ¡ticas de engenharia de dados.

---

## ğŸ§  VisÃ£o Geral da Arquitetura

Este projeto simula o funcionamento de uma **empresa de dados especializada em Analytics de Redes Sociais**, responsÃ¡vel por coletar, processar e disponibilizar mÃ©tricas de performance de vÃ­deos e conteÃºdos digitais para Ã¡reas de negÃ³cio e BI.

A arquitetura foi desenhada para ser:
- EscalÃ¡vel
- ReprocessÃ¡vel
- FÃ¡cil de operar
- Clara para pÃºblicos tÃ©cnicos e executivos

Fluxo resumido:

**IngestÃ£o â†’ Bronze â†’ Silver â†’ Gold â†’ PublicaÃ§Ã£o AnalÃ­tica â†’ VisualizaÃ§Ã£o**

A **camada Gold no S3** Ã© a *fonte da verdade analÃ­tica*. O banco relacional Ã© utilizado exclusivamente como **camada de serving**.

---

## ğŸ—ï¸ Componentes da Arquitetura

### 1. IngestÃ£o de Dados
- **Fonte**: Faker (dados sintÃ©ticos para simulaÃ§Ã£o)
- **FrequÃªncia**: 2x ao dia (08h e 20h)
- **Objetivo**: Gerar dados brutos para simular eventos/transaÃ§Ãµes

Os dados sÃ£o ingeridos sem transformaÃ§Ã£o e armazenados na camada Bronze.

---

### 2. Processamento de Dados â€“ Databricks / Spark

O processamento segue o padrÃ£o **Medallion Architecture**:

#### ğŸ¥‰ Bronze
- Formato: JSON
- Armazenamento: Amazon S3
- CaracterÃ­sticas:
  - Dados brutos
  - Sem tratamento
  - HistÃ³rico completo

#### ğŸ¥ˆ Silver
- Exemplo real neste projeto:
  - `silver_criacao_s3.csv`

Nesta camada, os dados representam **eventos de criaÃ§Ã£o/publicaÃ§Ã£o de conteÃºdos**, jÃ¡ tratados e padronizados para anÃ¡lises posteriores.
- Formato: Parquet
- Armazenamento: Amazon S3
- CaracterÃ­sticas:
  - Dados limpos e padronizados
  - Tipos corretos
  - Prontos para agregaÃ§Ãµes

#### ğŸ¥‡ Gold
- Exemplos reais neste projeto:
  - `gold_video_views_dia_rede_social.csv`
  - `gold_video_views_dia_faculdade.csv`

A camada Gold consolida **mÃ©tricas analÃ­ticas de redes sociais**, agregadas por dia, rede social e instituiÃ§Ã£o, prontas para consumo por BI.
- Formato: CSV
- Armazenamento: Amazon S3
- CaracterÃ­sticas:
  - Dados agregados
  - MÃ©tricas de negÃ³cio
  - Prontos para consumo analÃ­tico

â° **Janela de processamento**:
- Bronze â†’ Silver: 08h e 20h
- Silver â†’ Gold: 22h

---

### 3. PublicaÃ§Ã£o de Dados AnalÃ­ticos

ResponsÃ¡vel por disponibilizar os dados da **camada Gold** para consumo por ferramentas externas.

- **Tecnologia**: AWS Fargate
- **OrquestraÃ§Ã£o**: Amazon EventBridge
- **HorÃ¡rio**: 23h

FunÃ§Ã£o do processo:
- Ler dados da Gold no S3
- Carregar dados no banco analÃ­tico
- NÃ£o realiza transformaÃ§Ãµes de negÃ³cio

Esse processo Ã© chamado de:
> **PublicaÃ§Ã£o de Dados AnalÃ­ticos**

---

### 4. Banco AnalÃ­tico

- **Tecnologia**: PostgreSQL (Amazon RDS)
- **FunÃ§Ã£o**: Serving layer
- **CaracterÃ­sticas**:
  - Apenas leitura (BI / Apps)
  - Dados derivados da Gold
  - Pode ser recriado a qualquer momento

O banco **nÃ£o Ã© fonte da verdade**.

---

### 5. VisualizaÃ§Ã£o de Dados

Ferramentas de consumo:
- **Power BI**
- **Streamlit**

Essas ferramentas acessam exclusivamente o banco analÃ­tico, garantindo:
- Performance
- SeguranÃ§a
- Simplicidade de acesso

---

## ğŸ“¦ Estrutura do RepositÃ³rio (exemplo)

```
capstone-projetct-metrics/
â”œâ”€â”€ Docs/
â”‚   â”œâ”€â”€ arquitetura.png
â”‚   â””â”€â”€ ArquiteturaProjectCapstone.excalidraw
|
â”œâ”€â”€ Script/
â”‚   â””â”€â”€ Script_S3_to_RDS_Postegres.py
|
â”œâ”€â”€ Script_DDL/
|   â”œâ”€â”€ gold_video_views_dia_faculdade.sql
â”‚   â””â”€â”€ gold_video_views_dia_rede_social.sql
â”‚
â”œâ”€â”€ Notebook's/
â”œâ”€â”€â”€â”€â”€â”€ Bronze
â”‚       â””â”€â”€ bronze-faker-ingestao-s3.ipynb
â”œâ”€â”€â”€â”€â”€â”€ Silver
|       â””â”€â”€ silver-criacao-s3.ipynb
â”œâ”€â”€â”€â”€â”€â”€ Gold
|       â”œâ”€â”€ gold_video_views_dia_faculdade.ipynb
|       â””â”€â”€ gold_video_views_dia_rede_social.ipynb
|
â”œâ”€â”€ Pipiline_Jobs_Databricks
|   â”œâ”€â”€ Bronze_Silver.yaml
â”‚   â””â”€â”€ Gold.yaml
â”‚
â”œâ”€â”€ terraform/
â”‚   â””â”€â”€ terraform_rds_postgres.tf
â”‚
â”œâ”€â”€ .env.example
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

> âš ï¸ A estrutura pode variar conforme evoluÃ§Ã£o do projeto.

---

## ğŸš€ Como Executar (VisÃ£o Geral)

1. Executar ingestÃ£o de dados (Faker)
2. Processar dados no Databricks (Bronze â†’ Silver â†’ Gold)
3. Aguardar fechamento da Gold
4. Executar job de publicaÃ§Ã£o (Fargate)
5. Consumir dados via Power BI ou Streamlit

---

## ğŸ¯ Objetivos do Projeto

- Simular o funcionamento de uma **empresa de Analytics focada em Redes Sociais**
- Demonstrar como mÃ©tricas de vÃ­deos e engajamento podem ser tratadas e disponibilizadas
- Aplicar boas prÃ¡ticas de Lakehouse (Bronze / Silver / Gold)
- Separar claramente processamento analÃ­tico e serving
- Facilitar consumo por ferramentas de BI
- Servir como base para evoluÃ§Ãµes futuras (incremental, CDC, near real-time)

- Demonstrar arquitetura moderna de dados
- Aplicar boas prÃ¡ticas de Lakehouse
- Separar claramente processamento e serving
- Facilitar consumo analÃ­tico
- Servir como base para evoluÃ§Ãµes futuras (incremental, CDC, near real-time)

---

## ğŸ”® PrÃ³ximos Passos (EvoluÃ§Ãµes Naturais)

- Carga incremental na publicaÃ§Ã£o
- Upsert no banco analÃ­tico
- Controle de SLA por camada
- Observabilidade (logs e mÃ©tricas)
- CI/CD para pipelines

---

## ğŸ‘¥ PÃºblico-Alvo

- Engenheiros de Dados
- Analistas de Dados
- Arquitetos de Dados
- Times de BI
- Stakeholders tÃ©cnicos e de negÃ³cio

---

## ğŸ“Œ ObservaÃ§Ã£o Final

Este projeto foi construÃ­do com foco em **clareza arquitetural**, **boas prÃ¡ticas** e **facilidade de explicaÃ§Ã£o**, podendo ser utilizado como:
- Capstone project
- Prova de conceito
- ReferÃªncia interna de arquitetura

---

**Autor**: Orion Analytics  
**Projeto**: Capstone Metrics Platform

